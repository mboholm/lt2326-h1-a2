{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data, padding (based on 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M.B. ADDED EOS AND SOS\n",
    "\n",
    "def read_chinese_data(inputfilename):\n",
    "    with open(inputfilename, \"r\") as inputfile:\n",
    "        sentences = []\n",
    "        collection_words = []\n",
    "        collection_labels = []\n",
    "        for line in inputfile:\n",
    "            if line[0] == '#':\n",
    "                continue\n",
    "            columns = line.split()\n",
    "            #print(words)\n",
    "            if columns == []:\n",
    "                collection_words = [\"#\"] + collection_words + [\"!\"] # Neither \"#\" nor \"!\" seems to be in the original data\n",
    "                collection_labels = [1] + collection_labels + [1]\n",
    "\n",
    "                sentences.append((''.join(collection_words), collection_labels))\n",
    "                collection_words = []\n",
    "                collection_labels = []\n",
    "                continue\n",
    "            \n",
    "            collection_words.append(columns[1])\n",
    "            collection_labels += [1] + ([0] * (len(columns[1]) - 1))\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-train.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('#看似簡單，只是二選一做決擇，但其實他們代表的是你周遭的親朋好友，試著給你不同的意見，但追根究底，最後決定的還是自己。!',\n",
       " [1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-test.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('#然而，這樣的處理也衍生了一些問題。!',\n",
       " [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_chars(sentences):\n",
    "    megasentence = ''.join(sentences)\n",
    "    char_list = set()\n",
    "    for c in megasentence:\n",
    "        char_list.add(c)\n",
    "    char_list = [0] + list(char_list)\n",
    "    return char_list, {char_list[x]:x for x in range(len(char_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_index, char_index = index_chars([x[0] for x in train_sentences + test_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence(sentence, index):\n",
    "    return [index[x] for x in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_lengths(sentences, max_length, padding=0):\n",
    "    return [x + ([padding] * (max_length - len(x))) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(x, device=\"cpu\"):\n",
    "    converted = [(convert_sentence(x1[0], char_index), x1[1]) for x1 in x]\n",
    "    X, y = zip(*converted)\n",
    "    lengths = [len(x2) for x2 in X]\n",
    "    padded_X = pad_lengths(X, max(lengths))\n",
    "    Xt = torch.LongTensor(padded_X).to(device)\n",
    "    padded_y = pad_lengths(y, max(lengths), padding=-1)\n",
    "    yt = torch.LongTensor(padded_y).to(device)\n",
    "    lengths_t = torch.LongTensor(lengths).to(device)\n",
    "    return Xt, lengths_t, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tensor, train_lengths_tensor, train_y_tensor = create_dataset(train_sentences, gpu_device)\n",
    "test_X_tensor, test_lengths_tensor, test_y_tensor = create_dataset(test_sentences, gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packing the sequences for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testtensor = torch.randn((10,100,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlengths = torch.randint(1, 100, (10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), tensor([11, 80, 64,  6,  5, 46, 92, 19,  7, 16]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testlengths.size(), testlengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed = pack_padded_sequence(testtensor, testlengths, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3381,  1.4231, -1.2729,  ..., -0.1591,  0.6447,  0.8058],\n",
       "         [ 0.0374,  0.9253, -0.3206,  ...,  0.7357,  1.3738, -0.3904],\n",
       "         [ 1.6150,  0.3291, -0.5159,  ...,  0.1092, -1.0921,  1.8418],\n",
       "         ...,\n",
       "         [ 0.8254, -0.3407, -0.4572,  ..., -1.5870,  0.3455,  0.9807],\n",
       "         [-1.6292, -0.4160, -0.2796,  ...,  0.7870, -0.1446, -1.7183],\n",
       "         [-0.1003,  0.3343, -0.4830,  ...,  1.0632, -0.2810,  0.5121]],\n",
       "\n",
       "        [[-1.5954, -0.6897, -0.8975,  ..., -1.1709,  0.2712,  0.6628],\n",
       "         [ 0.0032,  1.1217, -0.0597,  ...,  0.7866,  0.6107,  0.0823],\n",
       "         [ 0.4865,  1.3972, -0.3719,  ..., -0.2553,  1.9099, -0.6933],\n",
       "         ...,\n",
       "         [-0.7236,  1.5181,  0.2994,  ...,  0.2475, -0.9312,  0.8596],\n",
       "         [-0.4899, -0.9239,  0.3771,  ..., -1.8857,  0.3889,  1.0718],\n",
       "         [ 0.4870,  0.3071,  0.4685,  ..., -1.6847, -1.0409,  1.1063]],\n",
       "\n",
       "        [[ 1.0053,  1.6845, -0.2428,  ...,  0.4258, -1.4855, -1.6009],\n",
       "         [-1.2082, -0.5886,  1.4736,  ..., -0.0632,  0.2265, -0.5315],\n",
       "         [ 0.1127,  0.6609, -0.0231,  ...,  0.7151, -0.8163,  0.6933],\n",
       "         ...,\n",
       "         [-0.4748, -0.2866,  1.3385,  ..., -0.6774, -1.8415, -1.1186],\n",
       "         [ 0.8411,  2.3424,  0.2593,  ...,  0.8636, -1.7573,  1.6250],\n",
       "         [-0.0184,  1.0991,  1.3577,  ...,  0.1298,  0.0421,  0.3803]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.1904,  0.5050, -0.2461,  ...,  1.3694,  0.6711, -0.9724],\n",
       "         [ 0.9931, -0.5070, -0.6835,  ...,  0.2875, -0.2019, -0.1087],\n",
       "         [-1.0458,  1.3869, -0.5404,  ..., -0.7074,  0.7938, -0.5161],\n",
       "         ...,\n",
       "         [-0.7040,  1.2849,  0.4724,  ...,  1.0721,  0.5332, -0.1217],\n",
       "         [-0.6590, -0.0293, -1.6557,  ..., -0.1719,  1.0415,  0.6075],\n",
       "         [ 2.4939, -0.1887, -0.0623,  ..., -1.1378, -1.2562,  0.3404]],\n",
       "\n",
       "        [[-0.3005,  0.0322,  0.3990,  ...,  0.4402, -1.1934, -0.4019],\n",
       "         [-0.4649,  1.1970, -1.8128,  ..., -0.2094, -0.9562, -2.3349],\n",
       "         [-0.4042, -0.1196, -1.5860,  ..., -0.7213,  1.0582,  1.6775],\n",
       "         ...,\n",
       "         [ 0.7948, -0.1938,  1.2345,  ..., -0.0107, -0.1094, -0.6116],\n",
       "         [-2.1715,  1.1532,  0.0928,  ...,  2.0609,  0.2993, -0.0969],\n",
       "         [-0.8944, -2.1081, -1.0253,  ..., -2.4583, -2.2895, -0.0669]],\n",
       "\n",
       "        [[ 2.5904,  0.4818, -1.0951,  ..., -1.6546,  0.0127,  0.6105],\n",
       "         [ 0.5551,  0.8371,  1.3882,  ...,  0.5418,  1.5362, -0.3347],\n",
       "         [ 2.7452,  0.9579, -0.4745,  ...,  1.7962,  0.8651,  1.4729],\n",
       "         ...,\n",
       "         [ 1.2439, -0.2864, -0.0099,  ...,  1.1282, -0.6928, -1.4915],\n",
       "         [ 0.2242,  0.3634, -0.5382,  ...,  0.1528, -0.0732,  0.8992],\n",
       "         [ 0.3368,  0.0378, -0.4573,  ...,  1.6174, -0.0518,  0.4543]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-1.3915, -1.9651, -0.9901,  ..., -1.0428, -1.1345, -0.4808],\n",
       "        [-1.5954, -0.6897, -0.8975,  ..., -1.1709,  0.2712,  0.6628],\n",
       "        [ 1.0053,  1.6845, -0.2428,  ...,  0.4258, -1.4855, -1.6009],\n",
       "        ...,\n",
       "        [ 1.9392, -1.4932, -1.0068,  ...,  0.7419, -0.2789,  1.6851],\n",
       "        [-1.6433, -2.3043, -1.3880,  ...,  0.8675,  0.6456,  1.8945],\n",
       "        [-0.7986, -0.4688, -0.2021,  ..., -0.7548,  0.2733, -0.8903]]), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  8,  7,  7,  7,  7,  6,  6,  6,  6,  6,  5,  5,\n",
       "         5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1]), sorted_indices=tensor([6, 1, 2, 5, 7, 9, 0, 8, 3, 4]), unsorted_indices=tensor([6, 1, 2, 8, 9, 3, 0, 4, 7, 5]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(packed.batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked = pad_packed_sequence(packed, batch_first=True, total_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3381,  1.4231, -1.2729,  ..., -0.1591,  0.6447,  0.8058],\n",
       "          [ 0.0374,  0.9253, -0.3206,  ...,  0.7357,  1.3738, -0.3904],\n",
       "          [ 1.6150,  0.3291, -0.5159,  ...,  0.1092, -1.0921,  1.8418],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-1.5954, -0.6897, -0.8975,  ..., -1.1709,  0.2712,  0.6628],\n",
       "          [ 0.0032,  1.1217, -0.0597,  ...,  0.7866,  0.6107,  0.0823],\n",
       "          [ 0.4865,  1.3972, -0.3719,  ..., -0.2553,  1.9099, -0.6933],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 1.0053,  1.6845, -0.2428,  ...,  0.4258, -1.4855, -1.6009],\n",
       "          [-1.2082, -0.5886,  1.4736,  ..., -0.0632,  0.2265, -0.5315],\n",
       "          [ 0.1127,  0.6609, -0.0231,  ...,  0.7151, -0.8163,  0.6933],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.1904,  0.5050, -0.2461,  ...,  1.3694,  0.6711, -0.9724],\n",
       "          [ 0.9931, -0.5070, -0.6835,  ...,  0.2875, -0.2019, -0.1087],\n",
       "          [-1.0458,  1.3869, -0.5404,  ..., -0.7074,  0.7938, -0.5161],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.3005,  0.0322,  0.3990,  ...,  0.4402, -1.1934, -0.4019],\n",
       "          [-0.4649,  1.1970, -1.8128,  ..., -0.2094, -0.9562, -2.3349],\n",
       "          [-0.4042, -0.1196, -1.5860,  ..., -0.7213,  1.0582,  1.6775],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 2.5904,  0.4818, -1.0951,  ..., -1.6546,  0.0127,  0.6105],\n",
       "          [ 0.5551,  0.8371,  1.3882,  ...,  0.5418,  1.5362, -0.3347],\n",
       "          [ 2.7452,  0.9579, -0.4745,  ...,  1.7962,  0.8651,  1.4729],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]),\n",
       " tensor([11, 80, 64,  6,  5, 46, 92, 19,  7, 16]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3381,  1.4231, -1.2729,  ..., -0.1591,  0.6447,  0.8058],\n",
       "         [ 0.0374,  0.9253, -0.3206,  ...,  0.7357,  1.3738, -0.3904],\n",
       "         [ 1.6150,  0.3291, -0.5159,  ...,  0.1092, -1.0921,  1.8418],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.5954, -0.6897, -0.8975,  ..., -1.1709,  0.2712,  0.6628],\n",
       "         [ 0.0032,  1.1217, -0.0597,  ...,  0.7866,  0.6107,  0.0823],\n",
       "         [ 0.4865,  1.3972, -0.3719,  ..., -0.2553,  1.9099, -0.6933],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.0053,  1.6845, -0.2428,  ...,  0.4258, -1.4855, -1.6009],\n",
       "         [-1.2082, -0.5886,  1.4736,  ..., -0.0632,  0.2265, -0.5315],\n",
       "         [ 0.1127,  0.6609, -0.0231,  ...,  0.7151, -0.8163,  0.6933],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.1904,  0.5050, -0.2461,  ...,  1.3694,  0.6711, -0.9724],\n",
       "         [ 0.9931, -0.5070, -0.6835,  ...,  0.2875, -0.2019, -0.1087],\n",
       "         [-1.0458,  1.3869, -0.5404,  ..., -0.7074,  0.7938, -0.5161],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3005,  0.0322,  0.3990,  ...,  0.4402, -1.1934, -0.4019],\n",
       "         [-0.4649,  1.1970, -1.8128,  ..., -0.2094, -0.9562, -2.3349],\n",
       "         [-0.4042, -0.1196, -1.5860,  ..., -0.7213,  1.0582,  1.6775],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.5904,  0.4818, -1.0951,  ..., -1.6546,  0.0127,  0.6105],\n",
       "         [ 0.5551,  0.8371,  1.3882,  ...,  0.5418,  1.5362, -0.3347],\n",
       "         [ 2.7452,  0.9579, -0.4745,  ...,  1.7962,  0.8651,  1.4729],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 200])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching (based on 1.0, 1.1, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batcher:\n",
    "    def __init__(self, X, lengths, y, device, batch_size=50, max_iter=None):\n",
    "        self.X = X\n",
    "        self.lengths = lengths # We need the lengths to efficiently use the padding.\n",
    "        self.y = y\n",
    "        self.device = device\n",
    "        self.batch_size=batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.curr_iter = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.curr_iter == self.max_iter:\n",
    "            raise StopIteration\n",
    "        permutation = torch.randperm(self.X.size()[0], device=self.device)\n",
    "        permX = self.X[permutation]\n",
    "        permlengths = self.lengths[permutation]\n",
    "        permy = self.y[permutation]\n",
    "        splitX = torch.split(permX, self.batch_size)\n",
    "        splitlengths = torch.split(permlengths, self.batch_size)\n",
    "        splity = torch.split(permy, self.batch_size)\n",
    "        \n",
    "        self.curr_iter += 1\n",
    "        return zip(splitX, splitlengths, splity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Batcher(train_X_tensor, train_lengths_tensor, train_y_tensor, torch.device('cuda:2'), max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbatching = next(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f3529153500>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbatch = next(testbatching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2428, 1228, 1539,  ...,    0,    0,    0],\n",
       "         [2428, 1989, 1417,  ...,    0,    0,    0],\n",
       "         [2428, 3061, 2458,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [2428, 2614,  205,  ...,    0,    0,    0],\n",
       "         [2428,  834, 2368,  ...,    0,    0,    0],\n",
       "         [2428, 2868,  867,  ...,    0,    0,    0]], device='cuda:2'),\n",
       " tensor([ 23, 105, 119,  30,  70,  47,  28,  42,  62,  27,  33,  28,  32,  24,\n",
       "          23,  31,  27,  50,  53,  36,  49,  25,  32,  41,  57,  36,  22,  29,\n",
       "          43,  69,  27,  42,  29,  30,  21,  32,  46,  32,  50,  64,  33,  33,\n",
       "          65,  52,  47,  34,  26,  38,  55,  74], device='cuda:2'),\n",
       " tensor([[ 1,  1,  0,  ..., -1, -1, -1],\n",
       "         [ 1,  1,  0,  ..., -1, -1, -1],\n",
       "         [ 1,  1,  0,  ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 1,  1,  0,  ..., -1, -1, -1],\n",
       "         [ 1,  1,  1,  ..., -1, -1, -1],\n",
       "         [ 1,  1,  0,  ..., -1, -1, -1]], device='cuda:2'))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(len(int_index), 200, 0).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testlengths, testy = testbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "testembs = emb(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4169,  1.8828, -2.2950,  ..., -2.0365, -1.4630,  0.5553],\n",
       "         [-0.0169,  0.5137,  0.6609,  ...,  1.0977,  0.7271,  0.1527],\n",
       "         [-1.7369, -0.1292,  0.3776,  ...,  0.3213,  1.4994,  0.4147],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.4169,  1.8828, -2.2950,  ..., -2.0365, -1.4630,  0.5553],\n",
       "         [-0.3619, -0.3426,  1.5092,  ..., -1.0968, -0.3181, -0.6486],\n",
       "         [-2.2222, -0.2598,  0.8753,  ...,  0.9435, -1.1886,  0.5207],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.4169,  1.8828, -2.2950,  ..., -2.0365, -1.4630,  0.5553],\n",
       "         [-0.3821, -1.3688,  1.8044,  ..., -1.9879,  1.0693,  0.2329],\n",
       "         [ 0.3630,  2.0832,  0.7989,  ..., -1.2206, -0.8685,  0.0752],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4169,  1.8828, -2.2950,  ..., -2.0365, -1.4630,  0.5553],\n",
       "         [ 0.8390, -0.0916,  2.6032,  ..., -0.2259, -0.1036, -0.4801],\n",
       "         [ 0.4317, -0.1030,  1.1033,  ..., -0.7396, -0.9100,  1.7915],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.4169,  1.8828, -2.2950,  ..., -2.0365, -1.4630,  0.5553],\n",
       "         [ 0.6484,  0.6870, -0.0336,  ..., -0.9074, -1.4081,  1.0533],\n",
       "         [-0.3745,  1.2949, -0.4051,  ...,  0.2375,  0.6513, -1.3977],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.4169,  1.8828, -2.2950,  ..., -2.0365, -1.4630,  0.5553],\n",
       "         [ 1.0242, -0.7614, -0.1011,  ..., -1.0574, -0.5018,  0.8221],\n",
       "         [-0.4073, -0.8266, -0.0049,  ..., -0.6214,  1.1804, -0.4617],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:2', grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testembs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 184, 200])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testembs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testembs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlstm = nn.LSTM(200, 150, batch_first=True).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "testembspadded = pack_padded_sequence(testembs, testlengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput, teststate = testlstm(testembspadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.0052,  0.0327, -0.1128,  ...,  0.0715, -0.2786, -0.0333],\n",
       "        [ 0.0052,  0.0327, -0.1128,  ...,  0.0715, -0.2786, -0.0333],\n",
       "        [ 0.0052,  0.0327, -0.1128,  ...,  0.0715, -0.2786, -0.0333],\n",
       "        ...,\n",
       "        [ 0.1627,  0.0300, -0.0569,  ...,  0.0222, -0.0025,  0.2308],\n",
       "        [ 0.1077,  0.1384, -0.0814,  ...,  0.0880,  0.2035,  0.2296],\n",
       "        [ 0.0341, -0.0247,  0.0058,  ..., -0.1464,  0.0199,  0.3771]],\n",
       "       device='cuda:2', grad_fn=<CudnnRnnBackward>), batch_sizes=tensor([50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "        50, 50, 50, 49, 48, 46, 45, 44, 43, 40, 38, 36, 34, 33, 29, 26, 25, 25,\n",
       "        23, 23, 22, 22, 22, 21, 19, 18, 18, 18, 17, 15, 15, 14, 12, 12, 11, 10,\n",
       "        10,  9,  9,  8,  8,  8,  8,  8,  7,  7,  6,  5,  5,  5,  5,  4,  3,  3,\n",
       "         3,  3,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]), sorted_indices=tensor([ 2,  1, 49,  4, 29, 42, 39,  8, 24, 48, 18, 43, 38, 17, 20,  5, 44, 36,\n",
       "        28, 31,  7, 23, 47, 25, 19, 45, 10, 41, 40, 22, 12, 37, 35, 15,  3, 33,\n",
       "        32, 27,  6, 11, 30, 16,  9, 46, 21, 13,  0, 14, 26, 34],\n",
       "       device='cuda:2'), unsorted_indices=tensor([46,  1,  0, 34,  3, 15, 38, 20,  7, 42, 26, 39, 30, 45, 47, 33, 41, 13,\n",
       "        10, 24, 14, 44, 29, 21,  8, 23, 48, 37, 18,  4, 40, 19, 36, 35, 49, 32,\n",
       "        17, 31, 12,  6, 28, 27,  5, 11, 16, 25, 43, 22,  9,  2],\n",
       "       device='cuda:2'))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "testunpacked = pad_packed_sequence(testoutput, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 119, 150])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testunpacked[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsigm = nn.Sigmoid().to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput2 = testsigm(testunpacked[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 119, 150])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testoutput2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlin = nn.Linear(150, 2).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput3 = testlin(testoutput2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 119, 2])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testoutput3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsoft = nn.LogSoftmax(2).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput4 = testsoft(testoutput3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0098, -0.4530],\n",
       "         [-0.9859, -0.4670],\n",
       "         [-0.9712, -0.4758],\n",
       "         ...,\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834]],\n",
       "\n",
       "        [[-1.0098, -0.4530],\n",
       "         [-0.9968, -0.4605],\n",
       "         [-0.9550, -0.4859],\n",
       "         ...,\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834]],\n",
       "\n",
       "        [[-1.0098, -0.4530],\n",
       "         [-0.9873, -0.4661],\n",
       "         [-0.9529, -0.4871],\n",
       "         ...,\n",
       "         [-0.9827, -0.4689],\n",
       "         [-0.9670, -0.4784],\n",
       "         [-0.9787, -0.4713]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.0098, -0.4530],\n",
       "         [-0.9991, -0.4592],\n",
       "         [-0.9732, -0.4746],\n",
       "         ...,\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834]],\n",
       "\n",
       "        [[-1.0098, -0.4530],\n",
       "         [-1.0059, -0.4553],\n",
       "         [-0.9509, -0.4884],\n",
       "         ...,\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834]],\n",
       "\n",
       "        [[-1.0098, -0.4530],\n",
       "         [-0.9977, -0.4600],\n",
       "         [-0.9677, -0.4780],\n",
       "         ...,\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834],\n",
       "         [-0.9590, -0.4834]]], device='cuda:2', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testoutput4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_short = testy[:, :max(testlengths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  0,  ..., -1, -1, -1],\n",
       "        [ 1,  1,  0,  ..., -1, -1, -1],\n",
       "        [ 1,  1,  0,  ...,  0,  1,  1],\n",
       "        ...,\n",
       "        [ 1,  1,  0,  ..., -1, -1, -1],\n",
       "        [ 1,  1,  1,  ..., -1, -1, -1],\n",
       "        [ 1,  1,  0,  ..., -1, -1, -1]], device='cuda:2')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 119])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy_short.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(119, device='cuda:2')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(testlengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpermuted = testoutput4.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0098, -0.9859, -0.9712,  ..., -0.9590, -0.9590, -0.9590],\n",
       "         [-0.4530, -0.4670, -0.4758,  ..., -0.4834, -0.4834, -0.4834]],\n",
       "\n",
       "        [[-1.0098, -0.9968, -0.9550,  ..., -0.9590, -0.9590, -0.9590],\n",
       "         [-0.4530, -0.4605, -0.4859,  ..., -0.4834, -0.4834, -0.4834]],\n",
       "\n",
       "        [[-1.0098, -0.9873, -0.9529,  ..., -0.9827, -0.9670, -0.9787],\n",
       "         [-0.4530, -0.4661, -0.4871,  ..., -0.4689, -0.4784, -0.4713]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.0098, -0.9991, -0.9732,  ..., -0.9590, -0.9590, -0.9590],\n",
       "         [-0.4530, -0.4592, -0.4746,  ..., -0.4834, -0.4834, -0.4834]],\n",
       "\n",
       "        [[-1.0098, -1.0059, -0.9509,  ..., -0.9590, -0.9590, -0.9590],\n",
       "         [-0.4530, -0.4553, -0.4884,  ..., -0.4834, -0.4834, -0.4834]],\n",
       "\n",
       "        [[-1.0098, -0.9977, -0.9677,  ..., -0.9590, -0.9590, -0.9590],\n",
       "         [-0.4530, -0.4600, -0.4780,  ..., -0.4834, -0.4834, -0.4834]]],\n",
       "       device='cuda:2', grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpermuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllloss = nn.NLLLoss(ignore_index=-1).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6605, device='cuda:2', grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nllloss(testpermuted, testy_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MB added variable for hidden dim\n",
    "class Segmenter(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden = hidden_dim\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_size, 0)\n",
    "        self.lstm = nn.LSTM(self.emb_size, self.hidden, batch_first=True)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.lin = nn.Linear(self.hidden, 2)\n",
    "        self.softmax = nn.LogSoftmax(2)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        embs = self.emb(x)\n",
    "        packed = pack_padded_sequence(embs, lengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "        output1, _ = self.lstm(packed)\n",
    "        unpacked, _ = pad_packed_sequence(output1, batch_first=True)\n",
    "        output2 = self.sig1(unpacked)\n",
    "        output3 = self.lin(output2)\n",
    "        return self.softmax(output3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M.B. NEW!\n",
    "\n",
    "class PredictNext(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_dim):\n",
    "        super(PredictNext, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden = hidden_dim\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_size, 0)\n",
    "        self.lstm = nn.LSTM(self.emb_size, self.hidden, batch_first=True)\n",
    "        self.classifier = nn.Linear(self.hidden, self.vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(1) # MB correct dimension?\n",
    "\n",
    "    def forward(self, previous, h_c_states): # M.B. removed lengths\n",
    "        \n",
    "        bsz = previous.shape[0]\n",
    "        \n",
    "        emb_previous = self.emb(previous)\n",
    "        #packed = pack_padded_sequence(embs, lengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "        output, (hidden, cell) = self.lstm(emb_previous, h_c_states)\n",
    "        \n",
    "        classification_over_vocabulary = self.classifier(hidden.reshape(bsz, self.hidden)) # MB length of input and output is 1\n",
    "        \n",
    "        classification_over_vocabulary = self.softmax(classification_over_vocabulary)\n",
    "        \n",
    "        next_one = classification_over_vocabulary.argmax(1).unsqueeze(1)\n",
    "        #print(\"next_one\", next_one)\n",
    "        \n",
    "        return next_one, classification_over_vocabulary, (hidden, cell)\n",
    "    \n",
    "    def initHidden(self, batchsize, zero = True):\n",
    "        \n",
    "        if zero:\n",
    "            init_hidden = torch.zeros(1, batchsize, self.hidden, device = gpu_device) # for unstacked lstms; see https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "            init_cell = torch.zeros(1, batchsize, self.hidden, device = gpu_device)\n",
    "        else:\n",
    "            init_hidden = torch.rand(1, batchsize, self.hidden, device = gpu_device) # for unstacked lstms; see https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "            init_cell = torch.rand(1, batchsize, self.hidden, device = gpu_device)\n",
    "        \n",
    "        return init_hidden, init_cell           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M.B. New!\n",
    "# This basically memorizes sentences ... Not much of a language model. \n",
    "# We want to calculate the loss for every predciction, learning word sequences / associations; \n",
    "# but how to combine this objective with segmentation?\n",
    "\n",
    "import random\n",
    "\n",
    "class DoubleObjective(nn.Module):\n",
    "    def __init__(self, segmentation_model, text_generator):\n",
    "        super(DoubleObjective, self).__init__()\n",
    "        \n",
    "        self.segmenter = segmentation_model\n",
    "        self.generator = text_generator\n",
    "        \n",
    "    def forward(self, sentence, lengths, h_c_states, teacher = False, generate_only = False):\n",
    "        \n",
    "        # Objective: generation\n",
    "        bsz = sentence.shape[0] # batch size\n",
    "        seq_len = sentence.shape[1] # sequence length\n",
    "        \n",
    "        my_generation = torch.zeros(bsz, seq_len-1, self.generator.vocab_size).to(gpu_device) # seq_len -1 ?\n",
    "        the_who = sentence[:, 0].unsqueeze(1) # a column of start symbols; unsqueezed\n",
    "        \n",
    "        for i in range(seq_len-1):\n",
    "            #print(\"the_who\", i, the_who)\n",
    "            the_who, for_loss, h_c_states = self.generator(the_who, h_c_states)\n",
    "            #print(\"the_who\", i, the_who)\n",
    "            my_generation[:, i, :] = for_loss.squeeze()\n",
    "            \n",
    "            if teacher:\n",
    "                if random.random() < 0.5: # teacher force ratio = 0.5\n",
    "                    the_who = sentence[:, i].unsqueeze(1)        \n",
    "        \n",
    "        if generate_only:\n",
    "            return my_generation\n",
    "        \n",
    "        else:\n",
    "            segmentation = self.segmenter(sentence, lengths)\n",
    "            return segmentation, my_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MB New\n",
    "\n",
    "def train(X, lengths, y, vocab_size, emb_size, lstm_hidden_dim, batch_size, epochs, device, model=None):\n",
    "    b = Batcher(X, lengths, y, device, batch_size=batch_size, max_iter=epochs)\n",
    "    \n",
    "    if not model:\n",
    "        my_segmenter = Segmenter(vocab_size, emb_size, lstm_hidden_dim).to(device)\n",
    "        my_generator = PredictNext(vocab_size, emb_size, lstm_hidden_dim).to(device) # embedding size and hidden dimension of LSTm could have been diffferatniatied\n",
    "        m = DoubleObjective(my_segmenter, my_generator)\n",
    "    else:\n",
    "        m = model\n",
    "        \n",
    "    loss = nn.NLLLoss(ignore_index=-1)\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    epoch = 0\n",
    "    \n",
    "    for split in b:\n",
    "        tot_loss = 0\n",
    "        for batch in split:\n",
    "            \n",
    "            sentence = batch[0]\n",
    "            lengths = batch[1]\n",
    "            \n",
    "            bsz = sentence.shape[0]\n",
    "            seq_len = sentence.shape[1]\n",
    "            \n",
    "            init_hidden, init_cell = m.generator.initHidden(bsz)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            segmentation, sentence_generations = m(sentence, lengths, (init_hidden, init_cell), teacher = False)\n",
    "            \n",
    "            # Loss Objective 1            \n",
    "            trgs = batch[2]\n",
    "            loss_o1 = loss(segmentation.permute(0,2,1), trgs[:, :max(lengths)])\n",
    "            \n",
    "            # Loss Objective 2\n",
    "#             print(\"sent\", sentence.shape)\n",
    "#             print(\"genr\", sentence_generations.shape)\n",
    "            \n",
    "            loss_o2 = loss(sentence_generations.reshape(bsz * (seq_len-1), m.generator.vocab_size), \n",
    "                           sentence[:, 1:].flatten())\n",
    "            \n",
    "            total_batch_loss = loss_o1 + loss_o2\n",
    "            \n",
    "            tot_loss += total_batch_loss\n",
    "            total_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(\"Total loss in epoch {} is {}.\".format(epoch, tot_loss))\n",
    "        epoch += 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 268.77178955078125.\n"
     ]
    }
   ],
   "source": [
    "# MB clarified ...\n",
    "model = train(X = train_X_tensor, \n",
    "              lengths = train_lengths_tensor, \n",
    "              y = train_y_tensor, \n",
    "              vocab_size = len(int_index), \n",
    "              emb_size = 200, \n",
    "              lstm_hidden_dim = 150, \n",
    "              batch_size = 50, \n",
    "              epochs = 1, \n",
    "              device = gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "tensor([], device='cuda:2', size=(1, 0, 3650))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'next_one' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_704664/546395171.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnext_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_over_vocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'next_one' is not defined"
     ]
    }
   ],
   "source": [
    "# MB New\n",
    "def text_generator(prime_token = \"#\", detach_me = True):\n",
    "    model.eval()\n",
    "    \n",
    "    start_me_up = torch.tensor([[char_index[prime_token]]]).to(gpu_device)\n",
    "    print(start_me_up.shape)\n",
    "    \n",
    "    hidden_cell_states = model.generator.initHidden(1)\n",
    "    \n",
    "    gen = model(start_me_up, None, hidden_cell_states, generate_only=True)\n",
    "    \n",
    "    print(gen)\n",
    "    \n",
    "text_generator()    \n",
    "\n",
    "\n",
    "next_one, classification_over_vocabulary, (hidden, cell)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoubleObjective(\n",
       "  (segmenter): Segmenter(\n",
       "    (emb): Embedding(3650, 200, padding_idx=0)\n",
       "    (lstm): LSTM(200, 150, batch_first=True)\n",
       "    (sig1): Sigmoid()\n",
       "    (lin): Linear(in_features=150, out_features=2, bias=True)\n",
       "    (softmax): LogSoftmax(dim=2)\n",
       "  )\n",
       "  (generator): PredictNext(\n",
       "    (emb): Embedding(3650, 200, padding_idx=0)\n",
       "    (lstm): LSTM(200, 150, batch_first=True)\n",
       "    (classifier): Linear(in_features=150, out_features=3650, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rawpredictions = model(test_X_tensor, test_lengths_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawpredictions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawpredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.log2(0.9), math.log2(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(rawpredictions, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lengths_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectpreds = []\n",
    "collecty = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_X_tensor.size(0)):\n",
    "    collectpreds.append(predictions[i][:test_lengths_tensor[i]])\n",
    "    collecty.append(test_y_tensor[i][:test_lengths_tensor[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collecty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds = torch.cat(collectpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = torch.cat(collecty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = classes.float()\n",
    "allpreds = allpreds.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = sum(classes * allpreds)\n",
    "fp = sum(classes * (~allpreds.bool()).float())\n",
    "tn = sum((~classes.bool()).float() * (~allpreds.bool()).float())\n",
    "fn = sum((~classes.bool()).float() * allpreds)\n",
    "\n",
    "tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = tp / (tp + fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tp / (tp + fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = (2 * recall * precision) / (recall + precision)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
