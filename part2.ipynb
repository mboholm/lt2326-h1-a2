{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data, padding (based on 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M.B. ADDED EOS AND SOS\n",
    "\n",
    "def read_chinese_data(inputfilename):\n",
    "    with open(inputfilename, \"r\") as inputfile:\n",
    "        sentences = []\n",
    "        collection_words = []\n",
    "        collection_labels = []\n",
    "        for line in inputfile:\n",
    "            if line[0] == '#':\n",
    "                collection_words.append(\"<sos>\")\n",
    "                collection_labels += 0 # for <sos>\n",
    "                continue\n",
    "            columns = line.split()\n",
    "            #print(words)\n",
    "            if columns == []:\n",
    "                collection_words.append(\"<eos>\")\n",
    "                collection_labels += 0 # for <eos>\n",
    "                sentences.append((''.join(collection_words), collection_labels))\n",
    "                collection_words = []\n",
    "                collection_labels = []\n",
    "                continue\n",
    "            \n",
    "            collection_words.append(columns[1])\n",
    "            collection_labels += [1] + ([0] * (len(columns[1]) - 1))\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/lt2316-h20-resources/zh_gsd-ud-train.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a9ab18df4a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_chinese_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/scratch/lt2316-h20-resources/zh_gsd-ud-train.conllu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-22b90594ed7c>\u001b[0m in \u001b[0;36mread_chinese_data\u001b[0;34m(inputfilename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_chinese_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minputfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcollection_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/lt2316-h20-resources/zh_gsd-ud-train.conllu'"
     ]
    }
   ],
   "source": [
    "train_sentences = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-train.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-test.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_chars(sentences):\n",
    "    megasentence = ''.join(sentences)\n",
    "    char_list = set()\n",
    "    for c in megasentence:\n",
    "        char_list.add(c)\n",
    "    char_list = [0] + list(char_list)\n",
    "    return char_list, {char_list[x]:x for x in range(len(char_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_index, char_index = index_chars([x[0] for x in train_sentences + test_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence(sentence, index):\n",
    "    return [index[x] for x in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_lengths(sentences, max_length, padding=0):\n",
    "    return [x + ([padding] * (max_length - len(x))) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(x, device=\"cpu\"):\n",
    "    converted = [(convert_sentence(x1[0], char_index), x1[1]) for x1 in x]\n",
    "    X, y = zip(*converted)\n",
    "    lengths = [len(x2) for x2 in X]\n",
    "    padded_X = pad_lengths(X, max(lengths))\n",
    "    Xt = torch.LongTensor(padded_X).to(device)\n",
    "    padded_y = pad_lengths(y, max(lengths), padding=-1)\n",
    "    yt = torch.LongTensor(padded_y).to(device)\n",
    "    lengths_t = torch.LongTensor(lengths).to(device)\n",
    "    return Xt, lengths_t, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tensor, train_lengths_tensor, train_y_tensor = create_dataset(train_sentences, \"cuda:2\")\n",
    "test_X_tensor, test_lengths_tensor, test_y_tensor = create_dataset(test_sentences, \"cuda:2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packing the sequences for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testtensor = torch.randn((10,100,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlengths = torch.randint(1, 100, (10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), tensor([73, 68, 69, 83,  2, 68, 15, 94, 92, 29]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testlengths.size(), testlengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed = pack_padded_sequence(testtensor, testlengths, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3460,  0.8601, -0.3602,  ..., -0.6606, -0.7232,  0.7644],\n",
       "         [-0.4885, -0.0430, -0.7172,  ..., -1.7140, -1.1623, -2.3424],\n",
       "         [ 0.2949, -0.3683,  0.5191,  ...,  0.8425, -0.5202, -0.8714],\n",
       "         ...,\n",
       "         [-0.2126,  1.6280, -1.1929,  ...,  1.5610, -3.0134, -0.7469],\n",
       "         [-0.6531, -0.7640, -0.9889,  ...,  0.9376,  2.5547, -0.3860],\n",
       "         [ 0.9178,  1.3750, -0.6420,  ..., -1.3148, -1.0334, -0.7716]],\n",
       "\n",
       "        [[-1.2386, -0.1902,  0.1670,  ..., -0.3830, -1.5681,  0.8615],\n",
       "         [ 0.7394, -1.6508,  1.7000,  ..., -1.2159,  1.8590,  2.0178],\n",
       "         [ 0.7880, -0.3599,  0.8885,  ...,  0.2828, -1.0034,  1.7312],\n",
       "         ...,\n",
       "         [ 0.7475, -0.8751,  2.2137,  ...,  0.6900,  0.1713, -0.7654],\n",
       "         [ 0.8935,  0.2210, -1.2117,  ...,  0.3842,  0.6095,  1.9627],\n",
       "         [ 0.4656, -0.0174,  0.1629,  ...,  0.9089, -0.3880,  0.3343]],\n",
       "\n",
       "        [[-1.2466, -0.4169, -0.8498,  ...,  0.0154, -0.3796,  0.5117],\n",
       "         [ 1.7032, -1.2075, -0.3918,  ...,  1.2199,  1.9046,  1.5462],\n",
       "         [-0.8215,  0.3139,  2.7157,  ..., -0.8299, -0.6534, -0.5515],\n",
       "         ...,\n",
       "         [-0.1962, -0.5234, -0.2154,  ..., -1.3188,  1.8740,  1.5544],\n",
       "         [ 0.2361, -1.9136,  1.3292,  ...,  2.2404, -1.8653, -0.8693],\n",
       "         [ 1.0031, -0.6358, -1.4047,  ...,  0.5123, -0.1275, -1.7687]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3851, -1.2286, -0.2241,  ..., -0.4248, -0.2921, -0.5316],\n",
       "         [ 1.1053, -0.6465,  1.0915,  ..., -0.1851, -1.2892, -0.0123],\n",
       "         [ 0.2191,  0.7056, -0.6088,  ..., -0.9997,  0.7320, -0.4437],\n",
       "         ...,\n",
       "         [ 0.2149,  2.0992, -2.1040,  ..., -1.4213,  1.1533,  1.4886],\n",
       "         [ 0.5855,  0.3935,  0.3466,  ...,  1.0658, -0.4355, -1.2669],\n",
       "         [-0.8939,  0.6716, -0.5161,  ...,  0.4754,  0.6100,  0.0404]],\n",
       "\n",
       "        [[-0.0207, -0.0781,  0.2259,  ..., -0.2573, -1.4404,  0.7890],\n",
       "         [ 1.9403,  0.6302,  1.1163,  ..., -0.6646, -0.5123, -0.0357],\n",
       "         [ 0.3005,  0.3789,  0.5381,  ...,  0.9053, -2.5440,  1.5195],\n",
       "         ...,\n",
       "         [-3.1335, -0.4940, -0.6783,  ..., -1.3977,  0.7097, -0.7231],\n",
       "         [-1.2651,  1.0712, -1.0285,  ..., -0.2227, -0.8646,  0.8370],\n",
       "         [ 0.7373, -1.0109,  1.6642,  ..., -0.3775, -0.2560,  0.9473]],\n",
       "\n",
       "        [[-1.2832,  0.7556,  0.7274,  ..., -0.8071,  1.1452, -1.4504],\n",
       "         [-0.5359, -1.9981,  1.5344,  ..., -0.9901,  0.3804,  0.6632],\n",
       "         [ 0.1763, -3.8258,  0.8552,  ..., -0.7392, -0.5905,  1.8451],\n",
       "         ...,\n",
       "         [-0.3832,  0.7217, -0.0915,  ...,  0.4740,  0.7695, -0.5207],\n",
       "         [-0.0176,  2.3068,  0.1314,  ...,  1.0846,  1.3124,  0.5227],\n",
       "         [ 0.4085,  1.7532, -0.4737,  ...,  0.5635,  1.2005,  0.5417]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.3851, -1.2286, -0.2241,  ..., -0.4248, -0.2921, -0.5316],\n",
       "        [-0.0207, -0.0781,  0.2259,  ..., -0.2573, -1.4404,  0.7890],\n",
       "        [-1.4782,  1.0978,  1.0463,  ..., -0.4727,  0.3425,  0.9615],\n",
       "        ...,\n",
       "        [-1.1854,  0.4523, -0.9268,  ..., -0.0390, -0.6158,  1.4851],\n",
       "        [ 1.2075,  0.0249,  1.5094,  ...,  0.6240,  0.7875, -1.1297],\n",
       "        [ 0.7120,  0.7570, -1.2365,  ...,  0.1983, -2.2814, -0.5015]]), batch_sizes=tensor([10, 10,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  5,  4,  4,  4,\n",
       "         4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  1,  1]), sorted_indices=tensor([7, 8, 3, 0, 2, 1, 5, 9, 6, 4]), unsorted_indices=tensor([3, 5, 4, 2, 9, 6, 8, 0, 1, 7]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(packed.batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked = pad_packed_sequence(packed, batch_first=True, total_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3460,  0.8601, -0.3602,  ..., -0.6606, -0.7232,  0.7644],\n",
       "          [-0.4885, -0.0430, -0.7172,  ..., -1.7140, -1.1623, -2.3424],\n",
       "          [ 0.2949, -0.3683,  0.5191,  ...,  0.8425, -0.5202, -0.8714],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-1.2386, -0.1902,  0.1670,  ..., -0.3830, -1.5681,  0.8615],\n",
       "          [ 0.7394, -1.6508,  1.7000,  ..., -1.2159,  1.8590,  2.0178],\n",
       "          [ 0.7880, -0.3599,  0.8885,  ...,  0.2828, -1.0034,  1.7312],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-1.2466, -0.4169, -0.8498,  ...,  0.0154, -0.3796,  0.5117],\n",
       "          [ 1.7032, -1.2075, -0.3918,  ...,  1.2199,  1.9046,  1.5462],\n",
       "          [-0.8215,  0.3139,  2.7157,  ..., -0.8299, -0.6534, -0.5515],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.3851, -1.2286, -0.2241,  ..., -0.4248, -0.2921, -0.5316],\n",
       "          [ 1.1053, -0.6465,  1.0915,  ..., -0.1851, -1.2892, -0.0123],\n",
       "          [ 0.2191,  0.7056, -0.6088,  ..., -0.9997,  0.7320, -0.4437],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.0207, -0.0781,  0.2259,  ..., -0.2573, -1.4404,  0.7890],\n",
       "          [ 1.9403,  0.6302,  1.1163,  ..., -0.6646, -0.5123, -0.0357],\n",
       "          [ 0.3005,  0.3789,  0.5381,  ...,  0.9053, -2.5440,  1.5195],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-1.2832,  0.7556,  0.7274,  ..., -0.8071,  1.1452, -1.4504],\n",
       "          [-0.5359, -1.9981,  1.5344,  ..., -0.9901,  0.3804,  0.6632],\n",
       "          [ 0.1763, -3.8258,  0.8552,  ..., -0.7392, -0.5905,  1.8451],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]),\n",
       " tensor([73, 68, 69, 83,  2, 68, 15, 94, 92, 29]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3460,  0.8601, -0.3602,  ..., -0.6606, -0.7232,  0.7644],\n",
       "         [-0.4885, -0.0430, -0.7172,  ..., -1.7140, -1.1623, -2.3424],\n",
       "         [ 0.2949, -0.3683,  0.5191,  ...,  0.8425, -0.5202, -0.8714],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.2386, -0.1902,  0.1670,  ..., -0.3830, -1.5681,  0.8615],\n",
       "         [ 0.7394, -1.6508,  1.7000,  ..., -1.2159,  1.8590,  2.0178],\n",
       "         [ 0.7880, -0.3599,  0.8885,  ...,  0.2828, -1.0034,  1.7312],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.2466, -0.4169, -0.8498,  ...,  0.0154, -0.3796,  0.5117],\n",
       "         [ 1.7032, -1.2075, -0.3918,  ...,  1.2199,  1.9046,  1.5462],\n",
       "         [-0.8215,  0.3139,  2.7157,  ..., -0.8299, -0.6534, -0.5515],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3851, -1.2286, -0.2241,  ..., -0.4248, -0.2921, -0.5316],\n",
       "         [ 1.1053, -0.6465,  1.0915,  ..., -0.1851, -1.2892, -0.0123],\n",
       "         [ 0.2191,  0.7056, -0.6088,  ..., -0.9997,  0.7320, -0.4437],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0207, -0.0781,  0.2259,  ..., -0.2573, -1.4404,  0.7890],\n",
       "         [ 1.9403,  0.6302,  1.1163,  ..., -0.6646, -0.5123, -0.0357],\n",
       "         [ 0.3005,  0.3789,  0.5381,  ...,  0.9053, -2.5440,  1.5195],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.2832,  0.7556,  0.7274,  ..., -0.8071,  1.1452, -1.4504],\n",
       "         [-0.5359, -1.9981,  1.5344,  ..., -0.9901,  0.3804,  0.6632],\n",
       "         [ 0.1763, -3.8258,  0.8552,  ..., -0.7392, -0.5905,  1.8451],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 200])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching (based on 1.0, 1.1, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batcher:\n",
    "    def __init__(self, X, lengths, y, device, batch_size=50, max_iter=None):\n",
    "        self.X = X\n",
    "        self.lengths = lengths # We need the lengths to efficiently use the padding.\n",
    "        self.y = y\n",
    "        self.device = device\n",
    "        self.batch_size=batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.curr_iter = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.curr_iter == self.max_iter:\n",
    "            raise StopIteration\n",
    "        permutation = torch.randperm(self.X.size()[0], device=self.device)\n",
    "        permX = self.X[permutation]\n",
    "        permlengths = self.lengths[permutation]\n",
    "        permy = self.y[permutation]\n",
    "        splitX = torch.split(permX, self.batch_size)\n",
    "        splitlengths = torch.split(permlengths, self.batch_size)\n",
    "        splity = torch.split(permy, self.batch_size)\n",
    "        \n",
    "        self.curr_iter += 1\n",
    "        return zip(splitX, splitlengths, splity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Batcher(train_X_tensor, train_lengths_tensor, train_y_tensor, torch.device('cuda:2'), max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbatching = next(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbatch = next(testbatching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(len(int_index), 200, 0).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testlengths, testy = testbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testembs = emb(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testembs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testembs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testembs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlstm = nn.LSTM(200, 150, batch_first=True).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testembspadded = pack_padded_sequence(testembs, testlengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput, teststate = testlstm(testembspadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testunpacked = pad_packed_sequence(testoutput, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testunpacked[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsigm = nn.Sigmoid().to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput2 = testsigm(testunpacked[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlin = nn.Linear(150, 2).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput3 = testlin(testoutput2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsoft = nn.LogSoftmax(2).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput4 = testsoft(testoutput3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoutput4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_short = testy[:, :max(testlengths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_short.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(testlengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpermuted = testoutput4.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpermuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllloss = nn.NLLLoss(ignore_index=-1).to(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllloss(testpermuted, testy_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MB added variable for hidden dim\n",
    "class Segmenter(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden = hidden_dim\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_size, 0)\n",
    "        self.lstm = nn.LSTM(self.emb_size, self.hidden, batch_first=True)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.lin = nn.Linear(self.hidden, 2)\n",
    "        self.softmax = nn.LogSoftmax(2)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        embs = self.emb(x)\n",
    "        packed = pack_padded_sequence(embs, lengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "        output1, _ = self.lstm(packed)\n",
    "        unpacked, _ = pad_packed_sequence(output1, batch_first=True)\n",
    "        output2 = self.sig1(unpacked)\n",
    "        output3 = self.lin(output2)\n",
    "        return self.softmax(output3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M.B. NEW!\n",
    "\n",
    "class PredictNext(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_dim):\n",
    "        super(PredictNext, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden = hidden_dim\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_size, 0)\n",
    "        self.lstm = nn.LSTM(self.emb_size, self.hidden, batch_first=True)\n",
    "        self.classifier = nn.Linear(self.hidden, self.vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(1) # MB correct dimension?\n",
    "\n",
    "    def forward(self, previous, hidden_state, cell_state, lengths): # M.B. removed lengths\n",
    "        \n",
    "        bsz = previous.shape[0]\n",
    "        \n",
    "        embs = self.emb(x)\n",
    "        #packed = pack_padded_sequence(embs, lengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "        output, (hidden, cell) = self.lstm(previous, (hidden, init))\n",
    "        \n",
    "        classification_over_vocabulary = classifier(hidden.reshape(bsz, self.hidden)) # MB length of input and output is 1\n",
    "        \n",
    "        classification_over_vocabulary = self.softmax(classification_over_vocabulary)\n",
    "        \n",
    "        next_one = classifcation_over_vocabulary.argmax(1)\n",
    "        \n",
    "        return next_one, classification_over_vocabulary, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M.B. New!\n",
    "\n",
    "class DoubleObjective(nn.Module):\n",
    "    def __init__(self, segmentation_model, text_generator):\n",
    "        super(DoubleObjective, self).__init__()\n",
    "        \n",
    "        self.segmenter = segmentation_model\n",
    "        self.generator = text_generator\n",
    "        \n",
    "    def forward(self, sentence, lengths, init_hidden, init_cell, teacher = False):\n",
    "        \n",
    "        # Objecive 1\n",
    "        segmentation = self.segmenter(sentence, lengths)\n",
    "        \n",
    "        # Objective 2\n",
    "        bsz = sentence.shape[0] # batch size\n",
    "        seq_len = sentence.shape[1] # sequence length\n",
    "        \n",
    "        my_generation = torch.zeros(batch_size, seq_len -1 , self.generator.vocab_size).to(device) # seq_len -1 ?\n",
    "        the_who = sentence[:, 0].unsqueeze(1) # a column of start symbols; unsqueezed\n",
    "        \n",
    "        hidden = (init_hidden, inti_cell)\n",
    "        \n",
    "        for i in range(seq_length):\n",
    "            the_who, for_loss, hidden = self.generator(the_who, hidden)\n",
    "            \n",
    "            my_generation[:, i, :] = for_loss.squeeze()\n",
    "            \n",
    "            if teacher:\n",
    "                if random.random() < 0.5: # teacher force ratio = 0.5\n",
    "                    the_who = sentence[:, i].unsqueeze(1)\n",
    "                \n",
    "        return segmentation, my_generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MB New\n",
    "\n",
    "def train(X, lengths, y, vocab_size, emb_size, lstm_hidden_dim, batch_size, epochs, device, model=None):\n",
    "    b = Batcher(X, lengths, y, device, batch_size=batch_size, max_iter=epochs)\n",
    "    \n",
    "    if not model:\n",
    "        my_segmenter = Segmenter(vocab_size, emb_size, lstm_hidden_dim).to(device)\n",
    "        my_generator = PredictNext(vocab_size, emb_size, lstm_hidden_dim).to(device) # embedding size and hidden dimension of LSTm could have been diffferatniatied\n",
    "        m = DoubleObjective(my_segmenter, my_generator)\n",
    "    else:\n",
    "        m = model\n",
    "        \n",
    "    loss = nn.NLLLoss(ignore_index=-1)\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    epoch = 0\n",
    "    \n",
    "    for split in b:\n",
    "        tot_loss = 0\n",
    "        for batch in split:\n",
    "            \n",
    "            bsz = batch.shape[0]\n",
    "            seq_len = batch.shape\n",
    "            init_hidden, init_cell = m.generator.initHidden(bsz)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            sent = batch[0]\n",
    "            lens = batch[1]\n",
    "            \n",
    "            segmentation, sentence_generations = m(sentence, lengths, init_hidden, init_cell, teacher = True)\n",
    "            \n",
    "            # Loss Objective 1            \n",
    "            trgs = batch[2]\n",
    "            loss_o1 = loss(segmentation.permute(0,2,1), trgs[:, :max(lens)])\n",
    "            \n",
    "            # Loss Objective 2\n",
    "            loss_o2 = loss(sentence_generations.reshape(bsz * sent.shape[1], m.vocab_size), sent.flatten())\n",
    "            \n",
    "            total_batch_loss = loss_o1 + loss_o2\n",
    "            \n",
    "            tot_loss += total_batch_loss\n",
    "            total_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(\"Total loss in epoch {} is {}.\".format(epoch, tot_loss))\n",
    "        epoch += 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MB clarified ...\n",
    "model = train(X = train_X_tensor, \n",
    "              lengths = train_lengths_tensor, \n",
    "              y = train_y_tensor, \n",
    "              vocab_size = len(int_index), \n",
    "              emb = size 200, \n",
    "              lstm_hidden_dim = 150, \n",
    "              batch_size = 50, \n",
    "              epochs = 30, \n",
    "              device = \"cuda:2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rawpredictions = model(test_X_tensor, test_lengths_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawpredictions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawpredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.log2(0.9), math.log2(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(rawpredictions, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lengths_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectpreds = []\n",
    "collecty = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_X_tensor.size(0)):\n",
    "    collectpreds.append(predictions[i][:test_lengths_tensor[i]])\n",
    "    collecty.append(test_y_tensor[i][:test_lengths_tensor[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collecty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds = torch.cat(collectpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = torch.cat(collecty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = classes.float()\n",
    "allpreds = allpreds.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = sum(classes * allpreds)\n",
    "fp = sum(classes * (~allpreds.bool()).float())\n",
    "tn = sum((~classes.bool()).float() * (~allpreds.bool()).float())\n",
    "fn = sum((~classes.bool()).float() * allpreds)\n",
    "\n",
    "tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = tp / (tp + fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tp / (tp + fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = (2 * recall * precision) / (recall + precision)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
